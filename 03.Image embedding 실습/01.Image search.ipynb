{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CLIP을 활용한 image-to-image search 구축\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zero-shot model : CLIP\n",
    "- 로컬 cache에 저장된 huggingface 캐쉬 삭제\n",
    "    - https://huggingface.co/docs/huggingface_hub/main/en/guides/cli\n",
    "    - pip install -U \"huggingface_hub[cli]\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# https://huggingface.co/\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `CLIPModel.from_pretrained`\n",
    "    - 모델 checkpoint 탐색\n",
    "    - 모델 weight 다운로드\n",
    "    - 모델 initialization\n",
    "    - 모델 meta data 로딩\n",
    "- `CLIPProcessor.from_pretrained`\n",
    "    - tokenizer, vocabulary 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = '03.Image_embedding_data/art_dataset/drawings/'\n",
    "image_paths = [os.path.join(folder, i) for i in list(os.walk('03.Image_embedding_data/art_dataset/drawings/'))[0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_images(images, texts=['', '', '', '', '']):\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "    for i in range(5):\n",
    "        axs[i].imshow(images[i])\n",
    "        axs[i].axis('off')\n",
    "        axs[i].text(0.5, -0.1, texts[i], va='bottom', ha='center', fontsize=10, transform=axs[i].transAxes)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(i) for i in image_paths[60:65]]\n",
    "draw_images(images,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image feature extraction\n",
    "- `model.get_image_features`\n",
    "- low level features\n",
    "    - edge, texture\n",
    "- mid level features\n",
    "    - low level feature를 종합\n",
    "    - shapes, patterns (특정 부품 등)\n",
    "- high level features\n",
    "    - object type, attribute, context\n",
    "    - 강아지/고양이, 누워있는/달리는, 배경 등\n",
    "- Relational and Positional Features\n",
    "    - 앞/뒤/위/아래\n",
    "- abstract concepts\n",
    "    - 텍스트와 이미지를 결합하여 이미지의 추상적인 '느낌'을 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_features(image_path, processor, model):\n",
    "    image = Image.open(image_path)\n",
    "    inputs = processor(images=image, return_tensors=\"pt\") # pytorch format\n",
    "    outputs = model.get_image_features(**inputs)\n",
    "    return outputs.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = [extract_img_features(i, processor, model) for i in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_image(query_feature, features, topk=10):\n",
    "    similarities = cosine_similarity(query_feature, torch.vstack(features)).flatten()\n",
    "    # sort in descending order\n",
    "    sorted_indices_desc = similarities.argsort()[::-1]\n",
    "    # 가장 유사도 높은 이미지는 제외 (query 이미지와 같은 이미지이기 때문)\n",
    "    topk_indices = sorted_indices_desc[1:topk+1]\n",
    "    # cosine similarities for the top-k indices\n",
    "    topk_similarities = similarities[topk_indices]\n",
    "\n",
    "    return topk_indices, topk_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = 10\n",
    "\n",
    "query_feature = image_features[query_id]\n",
    "most_similar_idx, distance = search_image(query_feature, image_features)\n",
    "\n",
    "print(\"input image :\")\n",
    "Image.open(image_paths[query_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽어오기\n",
    "similar_images = [Image.open(image_paths[i]) for i in most_similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_images(similar_images[:5], distance[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_images(similar_images[5:], distance[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한계점\n",
    "- 이미지 내부의 세부적인 디테일을 고려하지 못함\n",
    "\n",
    "### => 다음 시간에는... Image preprocessing을 통한 detailed search\n",
    "- Document를 문단/문장으로 나누는 것과 유사\n",
    "- 이미지에 들어있는 다양한 정보들을 \"chunking\"하여 개별적으로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--END--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastcampus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
